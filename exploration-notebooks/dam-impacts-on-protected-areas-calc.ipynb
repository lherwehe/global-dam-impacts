{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains functions that combine World Database of Protected Areas and Ramsar data for a country or continent to create a full protected areas dataset for the desired region and calculates the total length of rivers on protected lands and total area of protected lands that are affected by proposed dams by country for a desired continent. Below you will find the code to analyze Asia, Africa, and South America, you simply need to uncomment your selected continent and comment out deselected continents (running all three continents at once will likely crash your notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import earthpy as et\n",
    "import earthpy.plot as ep\n",
    "import contextily as ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check path and set working directory.\n",
    "wd_path = os.path.join(et.io.HOME, 'earth-analytics', 'data')\n",
    "if os.path.exists(wd_path):\n",
    "    os.chdir(wd_path)\n",
    "else:\n",
    "    print(\"Path does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/earth-analytics/data/earthpy-downloads/continent-country.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Data stored on figshare\n",
    "# Free flowing rivers current DOR\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23273213\")\n",
    "\n",
    "# Free flowing rivers future DOR\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23273216\")\n",
    "\n",
    "# World Database of Protected Areas Africa\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23354894\")\n",
    "\n",
    "# World Database of Protected Areas Asia\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23354900\")\n",
    "\n",
    "# World Database of Protected Areas South America\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23355335\")\n",
    "\n",
    "# World Database of Protected Areas Europe\n",
    "# et.data.get_data(url=\"https://ndownloader.figshare.com/files/23355098\")\n",
    "\n",
    "# World Database of Protected Areas North America\n",
    "# et.data.get_data(url=\"https://ndownloader.figshare.com/files/23355317\")\n",
    "\n",
    "# Ramsar Sites\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/22507082\")\n",
    "\n",
    "# Country boundaries\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/22507058\")\n",
    "\n",
    "# Continent boundaries\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23392280\")\n",
    "\n",
    "# Continent-country csv\n",
    "et.data.get_data(url=\"https://ndownloader.figshare.com/files/23393756\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custon Function\n",
    "def all_pa_continent(wdpa_polys, ramsar_polys, cont_name):\n",
    "    \"\"\" This function takes WDPA polygons for a continent and global ramsar polygons and returns a multipolygon feature \n",
    "    of the World Database of Protected Areas merged with the ramsar areas for that continent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wdpa_polys: gdf\n",
    "        The feature with the WDPA polygons for the selected continent.\n",
    "    ramsar_polys: gdf\n",
    "        The feature with all global ramsar polygons.\n",
    "    cont_name: str\n",
    "        The name of the selected continent.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wdpa_ramsar: gdf\n",
    "        A gdf of both the ramsar and WDPA protected areas for the continent.\n",
    "    \"\"\"\n",
    "    # Remove ramsar areas from WDPA dataset\n",
    "    try:\n",
    "        wdpa_polys.set_index('DESIG', inplace=True)\n",
    "        wdpa_polys.drop(\n",
    "            \"Ramsar Site, Wetland of International Importance\", inplace=True)\n",
    "    except:\n",
    "        print('No ramsar areas in WDPA dataset.')\n",
    "\n",
    "    # Remove duplicates from WDPA dataset (areas tagged by both state and local authorities)\n",
    "    try:\n",
    "        wdpa_polys.set_index('NAME', inplace=True)\n",
    "        wdpa_polys.drop_duplicates(subset=None,\n",
    "                                   keep='first', inplace=False)\n",
    "    except:\n",
    "        print('No duplicates in the WDPA dataset.')\n",
    "\n",
    "    # Pull out the ramsar areas for the continent or country and merge with protected areas\n",
    "    ramsar_polys = ramsar_polys[ramsar_polys[\"continent\"] == cont_name]\n",
    "    wdpa_ramsar = wdpa_polys.append(ramsar_polys, 'sort=True')\n",
    "\n",
    "    return wdpa_ramsar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open continent & country borders & ISOs\n",
    "country_borders = gpd.read_file(os.path.join(wd_path, \"earthpy-downloads\", \"country-borders\",\n",
    "                                             \"99bfd9e7-bb42-4728-87b5-07f8c8ac631c2020328-1-1vef4ev.lu5nk.shp\"))\n",
    "\n",
    "continent_iso = pd.read_csv(os.path.join(wd_path, \"earthpy-downloads\",\n",
    "                                         \"continent-country.csv\"))\n",
    "\n",
    "continent_borders = gpd.read_file(os.path.join(wd_path, \"earthpy-downloads\", \"continent-poly\",\n",
    "                                               \"Continents.shp\"))\n",
    "\n",
    "# Reproject data to World Equidistant Cylindrical, datum WGS84, units meters, EPSG 4087\n",
    "country_borders = country_borders.to_crs('epsg:4087')\n",
    "continent_borders = continent_borders.to_crs('epsg:4087')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open ramsar areas\n",
    "ramsar_polys = gpd.read_file(os.path.join(\n",
    "    \"earthpy-downloads\", \"ramsar-site-data\", \"ramsar-boundaries\",\n",
    "    \"features_publishedPolygon.shp\"))\n",
    "\n",
    "# Rename ramsar columns to match WDPA\n",
    "try:\n",
    "    ramsar_polys = ramsar_polys.rename(\n",
    "        columns={\"iso3\": \"PARENT_ISO\", \"officialna\": \"NAME\", \"area_off\": \"Shape_Area\"})\n",
    "except:\n",
    "    print('Ramsar column names already match WDPA dataset.')\n",
    "\n",
    "# Merge continent names with ramsar data for analyzing by continent\n",
    "ramsar_polys = pd.merge(ramsar_polys, continent_iso,\n",
    "                        left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# Data cleaning - take only necessary ramsar columns\n",
    "ramsar_polys = ramsar_polys[['NAME', 'PARENT_ISO',\n",
    "                             'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# Reproject ramsar data to  World Equidistant Cylindrical, datum WGS84, units meters, EPSG 4087\n",
    "ramsar_polys = ramsar_polys.to_crs('epsg:4087')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open current DOR shapefiles\n",
    "dor_0to5 = gpd.read_file(os.path.join(wd_path,\n",
    "                                      \"earthpy-downloads\", \"DOR_Binned\", \"DOR_0to5.shp\"))\n",
    "dor_5to10 = gpd.read_file(os.path.join(wd_path,\n",
    "                                       \"earthpy-downloads\", \"DOR_Binned\", \"DOR_5to10.shp\"))\n",
    "dor_10to15 = gpd.read_file(os.path.join(wd_path,\n",
    "                                        \"earthpy-downloads\", \"DOR_Binned\", \"DOR_10to15.shp\"))\n",
    "dor_15to20 = gpd.read_file(os.path.join(wd_path,\n",
    "                                        \"earthpy-downloads\", \"DOR_Binned\", \"DOR_15to20.shp\"))\n",
    "dor_over20 = gpd.read_file(os.path.join(wd_path,\n",
    "                                        \"earthpy-downloads\", \"DOR_Binned\", \"DOR_over20.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to (1) calculating difference in DOR between planned and current, (2) pulling only rivers with class > 3,\n",
    "# (3) projecting rivers, (4) buffer by 1/100 km to become polys for overlay fuction, (5) pull only needed columns\n",
    "\n",
    "gdf_list = [dor_0to5, dor_5to10, dor_10to15, dor_15to20, dor_over20]\n",
    "river_list_prj = []\n",
    "\n",
    "for shp in gdf_list:\n",
    "    shp['DOR_DIFF'] = shp['DOR_PLA'] - shp['DOR']\n",
    "    shp = shp[shp.RIV_CLASS > 3]\n",
    "    shp = shp.to_crs('epsg:4087')\n",
    "    shp['geometry'] = shp.buffer(10)\n",
    "    shp = shp[['LENGTH_KM', 'RIV_ORD', 'RIV_CLASS', 'CONTINENT',\n",
    "               'ISO_NAME', 'BAS_NAME', 'DOR', 'DOR_PLA', 'DOR_DIFF', 'Shape_Leng', 'geometry']]\n",
    "    river_list_prj.append(shp)\n",
    "\n",
    "# Re-assign names based on list index\n",
    "dor_0to5 = river_list_prj[0]\n",
    "dor_5to10 = river_list_prj[1]\n",
    "dor_10to15 = river_list_prj[2]\n",
    "dor_15to20 = river_list_prj[3]\n",
    "dor_over20 = river_list_prj[4]\n",
    "\n",
    "# Concatanate all current rivers gdfs for easier analysis\n",
    "all_rivers = pd.concat([dor_0to5, dor_5to10, dor_10to15,\n",
    "                        dor_15to20, dor_over20], axis=0)\n",
    "\n",
    "# Remove rivers that have DOR_DIFF of 0\n",
    "all_rivers_lg = all_rivers[all_rivers.DOR_DIFF > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze South America\n",
    "# Open WDPA polygons\n",
    "wdpa_sa_polys = gpd.read_file(os.path.join(wd_path,\n",
    "                                           \"earthpy-downloads\", \"WDPA_S_America\", \"WDPA_S_America.shp\"))\n",
    "\n",
    "# Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "wdpa_sa_polys = wdpa_sa_polys[wdpa_sa_polys.geometry != None]\n",
    "\n",
    "# Merge continent names with WDPA data for analyzing by continent\n",
    "wdpa_sa_polys = pd.merge(wdpa_sa_polys, continent_iso,\n",
    "                        left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# Take only the columns we need\n",
    "wdpa_sa_polys = wdpa_sa_polys[[\n",
    "    'NAME', 'DESIG', 'PARENT_ISO', 'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# Reporject WDPA data\n",
    "wdpa_sa_polys = wdpa_sa_polys.to_crs('epsg:4087')\n",
    "\n",
    "# Get the combined WDPA & ramsar areas for selected continent\n",
    "wdpa_ramsar_sa = all_pa_continent(wdpa_sa_polys, ramsar_polys, \"South America\")\n",
    "\n",
    "# Getting river length affected\n",
    "# Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "river_overlap_sa = gpd.overlay(\n",
    "    wdpa_ramsar_sa, all_rivers_lg, how='intersection')\n",
    "\n",
    "# Getting protected areas affected\n",
    "# Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "pa_overlap_sa = gpd.overlay(\n",
    "    river_overlap_sa, wdpa_ramsar_sa, how='intersection')\n",
    "\n",
    "# Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "sa_countries = continent_iso[continent_iso.continent == 'South America']\n",
    "\n",
    "# Create empty lists\n",
    "country_sums = []\n",
    "area_sums = []\n",
    "countries = []\n",
    "\n",
    "# Sum up the total river length affected by country in the continent\n",
    "for country in sa_countries.ISO3:\n",
    "    country_sums.append((\n",
    "        river_overlap_sa.loc[river_overlap_sa['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "    area_sums.append((\n",
    "        pa_overlap_sa.loc[pa_overlap_sa['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "    countries.append(country)\n",
    "\n",
    " # Create a pandas dataframe of lengths and areas affected\n",
    "sa_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "                           'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/jovyan/earth-analytics/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cce39d7823aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa_affected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dam-project-outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sa_affected.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3202\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m         )\n\u001b[0;32m-> 3204\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             )\n\u001b[1;32m    190\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/jovyan/earth-analytics/data'"
     ]
    }
   ],
   "source": [
    "# We need to export the results so we can use it in a different notebook\n",
    "# sa_affected.to_csv(wd_path, 'dam-project-outputs', 'sa_affected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Affected_KM</th>\n",
       "      <th>Affected_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>910.0</td>\n",
       "      <td>8752586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BVT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRA</td>\n",
       "      <td>2542.0</td>\n",
       "      <td>124350126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country  Affected_KM  Affected_Area\n",
       "0     ARG        910.0      8752586.0\n",
       "1     BOL         80.0           41.0\n",
       "2     BVT          0.0            0.0\n",
       "3     BRA       2542.0    124350126.0\n",
       "4     CHL          0.0            0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_affected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze Africa\n",
    "# wdpa_africa_polys = gpd.read_file(os.path.join(wd_path,\n",
    "#                                                \"earthpy-downloads\", \"WDPA_Africa\", \"WDPA_Africa.shp\"))\n",
    "\n",
    "# # Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "# wdpa_africa_polys = wdpa_africa_polys[wdpa_africa_polys.geometry != None]\n",
    "\n",
    "# # Merge continent africames with WDPA data for aafricalyzing by continent\n",
    "# wdpa_africa_polys = pd.merge(wdpa_africa_polys, continent_iso,\n",
    "#                         left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# # Take only the columns we need\n",
    "# wdpa_africa_polys = wdpa_africa_polys[[\n",
    "#     'NAME', 'DESIG', 'PARENT_ISO', 'GIS_AREA', 'continent', 'geometry']]\n",
    "\n",
    "# # Reporject WDPA data\n",
    "# wdpa_africa_polys = wdpa_africa_polys.to_crs('epsg:4087')\n",
    "\n",
    "# # Get the combined WDPA & ramsar areas for selected continent\n",
    "# wdpa_ramsar_africa = all_pa_continent(wdpa_africa_polys, ramsar_polys, \"Africa\")\n",
    "\n",
    "# # Getting river length affected\n",
    "# # Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "# river_overlap_africa = gpd.overlay(\n",
    "#     wdpa_ramsar_africa, all_rivers_lg, how='intersection')\n",
    "\n",
    "# # Getting protected areas affected\n",
    "# # Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "# pa_overlap_africa = gpd.overlay(\n",
    "#     river_overlap_africa, wdpa_ramsar_africa, how='intersection')\n",
    "\n",
    "# # Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "# africa_countries = continent_iso[continent_iso.continent == 'Africa']\n",
    "\n",
    "# # Create empty lists\n",
    "# country_sums = []\n",
    "# area_sums = []\n",
    "# countries = []\n",
    "\n",
    "# # Sum up the total river length affected by country in the continent\n",
    "# for country in africa_countries.ISO3:\n",
    "#     country_sums.append((\n",
    "#         river_overlap_africa.loc[river_overlap_africa['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "#     area_sums.append((\n",
    "#         pa_overlap_africa.loc[pa_overlap_africa['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "#     countries.append(country)\n",
    "\n",
    "#  # Create a pandas dataframe of lengths and areas affected\n",
    "# africa_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "#                            'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze Asia\n",
    "# wdpa_asia_polys = gpd.read_file(os.path.join(wd_path,\n",
    "#                                              \"earthpy-downloads\", \"WDPA_Asia\", \"WDPA_Asia.shp\"))\n",
    "\n",
    "# # Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "# wdpa_asia_polys = wdpa_asia_polys[wdpa_asia_polys.geometry != None]\n",
    "\n",
    "# # Merge continent asiames with WDPA data for aasialyzing by continent\n",
    "# wdpa_asia_polys = pd.merge(wdpa_asia_polys, continent_iso,\n",
    "#                         left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# # Take only the columns we need\n",
    "# wdpa_asia_polys = wdpa_asia_polys[[\n",
    "#     'NAME', 'DESIG', 'PARENT_ISO', 'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# # Reporject WDPA data\n",
    "# wdpa_asia_polys = wdpa_asia_polys.to_crs('epsg:4087')\n",
    "\n",
    "# # Get the combined WDPA & ramsar areas for selected continent\n",
    "# wdpa_ramsar_asia = all_pa_continent(wdpa_asia_polys, ramsar_polys, \"Asia\")\n",
    "\n",
    "# # Getting river length affected\n",
    "# # Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "# river_overlap_asia = gpd.overlay(\n",
    "#     wdpa_ramsar_asia, all_rivers_lg, how='intersection')\n",
    "\n",
    "# # Getting protected areas affected\n",
    "# # Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "# pa_overlap_asia = gpd.overlay(\n",
    "#     river_overlap_asia, wdpa_ramsar_asia, how='intersection')\n",
    "\n",
    "# # Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "# asia_countries = continent_iso[continent_iso.continent == 'Asia']\n",
    "\n",
    "# # Create empty lists\n",
    "# country_sums = []\n",
    "# area_sums = []\n",
    "# countries = []\n",
    "\n",
    "# # Sum up the total river length affected by country in the continent\n",
    "# for country in asia_countries.ISO3:\n",
    "#     country_sums.append((\n",
    "#         river_overlap_asia.loc[river_overlap_asia['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "#     area_sums.append((\n",
    "#         pa_overlap_asia.loc[pa_overlap_asia['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "#     countries.append(country)\n",
    "\n",
    "#  # Create a pandas dataframe of lengths and areas affected\n",
    "# asia_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "#                            'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze North America - kernel dies, dataset too big?\n",
    "# wdpa_na_polys = gpd.read_file(os.path.join(wd_path,\n",
    "#                                            \"earthpy-downloads\", \"WDPA_N_America\", \"WDPA_N_America.shp\"))\n",
    "# # Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "# wdpa_na_polys = wdpa_na_polys[wdpa_na_polys.geometry != None]\n",
    "\n",
    "# # Merge continent names with WDPA data for analyzing by continent\n",
    "# wdpa_na_polys = pd.merge(wdpa_na_polys, continent_iso,\n",
    "#                         left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# # Take only the columns we need\n",
    "# wdpa_na_polys = wdpa_na_polys[[\n",
    "#     'NAME', 'DESIG', 'PARENT_ISO', 'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# # Reporject WDPA data\n",
    "# wdpa_na_polys = wdpa_na_polys.to_crs('epsg:4087')\n",
    "\n",
    "# # Get the combined WDPA & ramsar areas for selected continent\n",
    "# wdpa_ramsar_na = all_pa_continent(wdpa_na_polys, ramsar_polys, \"North America\")\n",
    "\n",
    "# # Getting river length affected\n",
    "# # Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "# river_overlap_na = gpd.overlay(\n",
    "#     wdpa_ramsar_na, all_rivers_lg, how='intersection')\n",
    "\n",
    "# # Getting protected areas affected\n",
    "# # Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "# pa_overlap_na = gpd.overlay(\n",
    "#     river_overlap_na, wdpa_ramsar_na, how='intersection')\n",
    "\n",
    "# # Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "# na_countries = continent_iso[continent_iso.continent == 'North America']\n",
    "\n",
    "# # Create empty lists\n",
    "# country_sums = []\n",
    "# area_sums = []\n",
    "# countries = []\n",
    "\n",
    "# # Sum up the total river length affected by country in the continent\n",
    "# for country in na_countries.ISO3:\n",
    "#     country_sums.append((\n",
    "#         river_overlap_na.loc[river_overlap_na['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "#     area_sums.append((\n",
    "#         pa_overlap_na.loc[pa_overlap_na['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "#     countries.append(country)\n",
    "\n",
    "#  # Create a pandas dataframe of lengths and areas affected\n",
    "# na_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "#                            'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze Europe - kernel dies, dataset too big?\n",
    "# wdpa_europe_polys = gpd.read_file(os.path.join(wd_path,\n",
    "#                                                \"earthpy-downloads\", \"WDPA_Europe\", \"WDPA_Europe.shp\"))\n",
    "\n",
    "# # Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "# wdpa_europe_polys = wdpa_europe_polys[wdpa_europe_polys.geometry != None]\n",
    "\n",
    "# # Merge continent names with WDPA data for analyzing by continent\n",
    "# wdpa_europe_polys = pd.merge(wdpa_europe_polys, continent_iso,\n",
    "#                         left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# # Take only the columns we need\n",
    "# wdpa_europe_polys = wdpa_europe_polys[[\n",
    "#     'NAME', 'DESIG', 'PARENT_ISO', 'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# # Reporject WDPA data\n",
    "# wdpa_europe_polys = wdpa_europe_polys.to_crs('epsg:4087')\n",
    "\n",
    "# # Get the combined WDPA & rameuroper areas for selected continent\n",
    "# wdpa_ramsar_europe = all_pa_continent(wdpa_europe_polys, ramsar_polys, \"Europe\")\n",
    "\n",
    "# # Getting river length affected\n",
    "# # Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "# river_overlap_europe = gpd.overlay(\n",
    "#     wdpa_rameuroper_europe, all_rivers_lg, how='intersection')\n",
    "\n",
    "# # Getting protected areas affected\n",
    "# # Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "# pa_overlap_europe = gpd.overlay(\n",
    "#     river_overlap_europe, wdpa_rameuroper_europe, how='intersection')\n",
    "\n",
    "# # Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "# europe_countries = continent_iso[continent_iso.continent == 'Europe']\n",
    "\n",
    "# # Create empty lists\n",
    "# country_sums = []\n",
    "# area_sums = []\n",
    "# countries = []\n",
    "\n",
    "# # Sum up the total river length affected by country in the continent\n",
    "# for country in europe_countries.ISO3:\n",
    "#     country_sums.append((\n",
    "#         river_overlap_europe.loc[river_overlap_europe['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "#     area_sums.append((\n",
    "#         pa_overlap_europe.loc[pa_overlap_europe['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "#     countries.append(country)\n",
    "\n",
    "#  # Create a pandas dataframe of lengths and areas affected\n",
    "# europe_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "#                            'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyze Australia - runs, however, there are no large rivers overlapping protected areas\n",
    "# wdpa_aus_polys = gpd.read_file(os.path.join(wd_path,\n",
    "#                                             \"earthpy-downloads\", \"WDPA_Australia\", \"WDPA_Australia.shp\"))\n",
    "\n",
    "# # Data cleaning - remove polygons with no area & take only the needed columns from WDPA dataset\n",
    "# wdpa_aus_polys = wdpa_aus_polys[wdpa_aus_polys.geometry != None]\n",
    "\n",
    "# # Merge continent ausmes with WDPA data for aauslyzing by continent\n",
    "# wdpa_aus_polys = pd.merge(wdpa_aus_polys, continent_iso,\n",
    "#                         left_on='PARENT_ISO', right_on='ISO3')\n",
    "\n",
    "# # Take only the columns we need\n",
    "# wdpa_aus_polys = wdpa_aus_polys[[\n",
    "#     'NAME', 'DESIG', 'PARENT_ISO', 'Shape_Area', 'continent', 'geometry']]\n",
    "\n",
    "# # Reporject WDPA data\n",
    "# wdpa_aus_polys = wdpa_aus_polys.to_crs('epsg:4087')\n",
    "\n",
    "# # Get the combined WDPA & ramsar areas for selected continent\n",
    "# wdpa_ramsar_aus = all_pa_continent(wdpa_aus_polys, ramsar_polys, \"Oceania\")\n",
    "\n",
    "# # Getting river length affected\n",
    "# # Overlay current rivers on protected areas for selected continent to get ONLY rivers the overlap PAs\n",
    "# river_overlap_aus = gpd.overlay(\n",
    "#     wdpa_ramsar_aus, all_rivers_lg, how='intersection')\n",
    "\n",
    "# # Getting protected areas affected\n",
    "# # Overlay projected rivers on pas for selected continent to get ONLY pas that overlap rivers\n",
    "# pa_overlap_aus = gpd.overlay(\n",
    "#     river_overlap_aus, wdpa_ramsar_aus, how='intersection')\n",
    "\n",
    "# # Get a list of countries in each continent for calculating lengths/areas by country later\n",
    "# aus_countries = continent_iso[continent_iso.continent == 'Oceania']\n",
    "\n",
    "# # Create empty lists\n",
    "# country_sums = []\n",
    "# area_sums = []\n",
    "# countries = []\n",
    "\n",
    "# # Sum up the total river length affected by country in the continent\n",
    "# for country in aus_countries.ISO3:\n",
    "#     country_sums.append((\n",
    "#         river_overlap_aus.loc[river_overlap_aus['PARENT_ISO'] == country, 'LENGTH_KM'].sum()).round(0))\n",
    "#     area_sums.append((\n",
    "#         pa_overlap_aus.loc[pa_overlap_aus['PARENT_ISO_1'] == country, 'Shape_Area_1'].sum()).round(0))\n",
    "#     countries.append(country)\n",
    "\n",
    "#  # Create a pandas dataframe of lengths and areas affected\n",
    "# aus_affected = pd.DataFrame(list(zip(countries, country_sums, area_sums)), columns=[\n",
    "#                            'Country', 'Affected_KM', 'Affected_Area'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
